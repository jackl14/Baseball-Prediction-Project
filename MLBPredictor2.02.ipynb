{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1331927f-1c74-47b9-af69-6ed786239f6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m binomtest\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binomtest\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from contextlib import redirect_stdout\n",
    "import io\n",
    "import sys\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras import layers\n",
    "from joblib import load\n",
    "\n",
    "\n",
    "# Create a StringIO object to capture stdout so that tensorflow doesn't print extra outputs\n",
    "stopper = io.StringIO()\n",
    "\n",
    "\n",
    "mlb_teams = {\n",
    "    'Arizona Diamondbacks': 'ARI',\n",
    "    'Atlanta Braves': 'ATL',\n",
    "    'Baltimore Orioles': 'BAL',\n",
    "    'Boston Red Sox': 'BOS',\n",
    "    'Chicago White Sox': 'CHW',\n",
    "    'Chicago Cubs': 'CHC',\n",
    "    'Cincinnati Reds': 'CIN',\n",
    "    'Cleveland Guardians': 'CLE',\n",
    "    'Colorado Rockies': 'COL',\n",
    "    'Detroit Tigers': 'DET',\n",
    "    'Houston Astros': 'HOU',\n",
    "    'Kansas City Royals': 'KCR',\n",
    "    'Los Angeles Angels': 'LAA',\n",
    "    'Los Angeles Dodgers': 'LAD',\n",
    "    'Miami Marlins': 'MIA',\n",
    "    'Milwaukee Brewers': 'MIL',\n",
    "    'Minnesota Twins': 'MIN',\n",
    "    'New York Yankees': 'NYY',\n",
    "    'New York Mets': 'NYM',\n",
    "    'Oakland Athletics': 'OAK',\n",
    "    'Philadelphia Phillies': 'PHI',\n",
    "    'Pittsburgh Pirates': 'PIT',\n",
    "    'San Diego Padres': 'SDP',\n",
    "    'San Francisco Giants': 'SFG',\n",
    "    'Seattle Mariners': 'SEA',\n",
    "    'St. Louis Cardinals': 'STL',\n",
    "    'Tampa Bay Rays': 'TBR',\n",
    "    'Texas Rangers': 'TEX',\n",
    "    'Toronto Blue Jays': 'TOR',\n",
    "    'Washington Nationals': 'WSN'\n",
    "}\n",
    "totals = {\n",
    "    'ARI': [0, 0],\n",
    "    'ATL': [0, 0],\n",
    "    'BAL': [0, 0],\n",
    "    'BOS': [0, 0],\n",
    "    'CHW': [0, 0],\n",
    "    'CHC': [0, 0],\n",
    "    'CIN': [0, 0],\n",
    "    'CLE': [0, 0],\n",
    "    'COL': [0, 0],\n",
    "    'DET': [0, 0],\n",
    "    'HOU': [0, 0],\n",
    "    'KCR': [0, 0],\n",
    "    'LAA': [0, 0],\n",
    "    'LAD': [0, 0],\n",
    "    'MIA': [0, 0],\n",
    "    'MIL': [0, 0],\n",
    "    'MIN': [0, 0],\n",
    "    'NYY': [0, 0],\n",
    "    'NYM': [0, 0],\n",
    "    'OAK': [0, 0],\n",
    "    'PHI': [0, 0],\n",
    "    'PIT': [0, 0],\n",
    "    'SDP': [0, 0],\n",
    "    'SFG': [0, 0],\n",
    "    'SEA': [0, 0],\n",
    "    'STL': [0, 0],\n",
    "    'TBR': [0, 0],\n",
    "    'TEX': [0, 0],\n",
    "    'TOR': [0, 0],\n",
    "    'WSN': [0, 0]\n",
    "}\n",
    "\n",
    "\n",
    "def extract_numbers(string):\n",
    "    numbers = re.findall(r'\\d+', string)\n",
    "    if len(numbers) >= 2:\n",
    "        return int(numbers[0]), int(numbers[1])\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def readInHistoricalData():\n",
    "  df = pd.read_csv(r\"C:\\Users\\Jack Leitzell\\Documents\\MLBDataframeWithRatingsAndScores.csv\")\n",
    "\n",
    "  #Getting rid of faulty entries\n",
    "  df.dropna(inplace=True)\n",
    "  df = df.drop(df[df.apply(lambda row: row.astype(str).str.contains('Not Found').any(), axis=1)].index)\n",
    "\n",
    "  return df\n",
    "\n",
    "def get_last_ratings(df_historical):\n",
    "    df = df_historical\n",
    "    ratings = {}\n",
    "\n",
    "    # Get unique team codes from the dataframe\n",
    "    teams = mlb_teams.values()\n",
    "\n",
    "    # Iterate over unique team codes to get the last rating for each team\n",
    "    for team_code in teams:\n",
    "      found = False\n",
    "      i = 1\n",
    "\n",
    "      while found == False:\n",
    "        i = i + 1\n",
    "        j = len(df) - i\n",
    "\n",
    "        try:\n",
    "\n",
    "          if df.loc[j,\"Home_ID\"] == team_code:\n",
    "            ratings[team_code] = df.loc[j,\"Home Rating\"]\n",
    "            found = True\n",
    "          elif df.loc[j,\"Away_ID\"] == team_code:\n",
    "            ratings[team_code] = df.loc[j,\"Away Rating\"]\n",
    "            found = True\n",
    "        except KeyError:\n",
    "          pass\n",
    "\n",
    "    return ratings\n",
    "\n",
    "def regressLastYearRatingsToMean():\n",
    "  for key in ratings:\n",
    "    ratings[key] = ratings[key] - (ratings[key] - 1500) / 2\n",
    "\n",
    "\n",
    "\n",
    "def scrapeLatestData():\n",
    "\n",
    "  #Scrapes 2024 game outcomes\n",
    "  r=requests.get(\"https://www.baseball-reference.com/leagues/majors/2024-schedule.shtml\")\n",
    "  parsing = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "  #Finds game entries\n",
    "  games = parsing.find_all('p', class_='game')\n",
    "\n",
    "  #Initialize lists\n",
    "  home_teams = []\n",
    "  away_teams = []\n",
    "  home_scores = []\n",
    "  away_scores = []\n",
    "\n",
    "  #Loop through games\n",
    "  for game in games:\n",
    "\n",
    "      #Extract team names\n",
    "      teams = game.find_all('a')\n",
    "      home_team = teams[0].text.strip()\n",
    "      away_team = teams[1].text.strip()\n",
    "\n",
    "      #Handle cases where game is in the future\n",
    "      gtext = game.text\n",
    "      if ':' not in gtext:\n",
    "\n",
    "        #Get scores\n",
    "        home_score, away_score = extract_numbers(gtext)\n",
    "        #Add to lists\n",
    "        home_teams.append(home_team)\n",
    "        away_teams.append(away_team)\n",
    "        home_scores.append(home_score)\n",
    "        away_scores.append(away_score)\n",
    "\n",
    "  # Create a Pandas DataFrame\n",
    "  data = {\n",
    "      'Home Team': home_teams,\n",
    "      'Away Team': away_teams,\n",
    "      'R Home': home_scores,\n",
    "      'R Away': away_scores\n",
    "  }\n",
    "\n",
    "  df = pd.DataFrame(data)\n",
    "\n",
    "  #Get rid of faulty rows\n",
    "  df.dropna(inplace=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "def populateTotals(dfnew):\n",
    "    #Populating the dictionary to find team average runs\n",
    "    for i in range(len(dfnew)+50):\n",
    "        try:\n",
    "            home_team = dfnew.loc[i, 'Home Team']\n",
    "            if home_team == \"Arizona D'Backs\":\n",
    "                home_team = \"Arizona Diamondbacks\"\n",
    "            home_code = mlb_teams[home_team]\n",
    "            away_team = dfnew.loc[i, 'Away Team']\n",
    "            if away_team == \"Arizona D'Backs\":\n",
    "                away_team = \"Arizona Diamondbacks\"\n",
    "            away_code = mlb_teams[away_team]\n",
    "            #Finding teams then summing their runs\n",
    "            totals[home_code][0] += dfnew.loc[i, 'R Home']\n",
    "            totals[away_code][0] += dfnew.loc[i, 'R Away']\n",
    "            #Counting games\n",
    "            totals[home_code][1] += 1\n",
    "            totals[away_code][1] += 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "\n",
    "def expectation(elo1,elo2): #That player 1 wins\n",
    "    #Elo equation\n",
    "    expectation = (1+10**((elo2-elo1)/400))**-1\n",
    "\n",
    "    return expectation\n",
    "\n",
    "def update_rating(expectation,player_rating,result,score1,score2,k):\n",
    "    #k = 20\n",
    "    normal_win_factor = 3.55 #This is the average value that a team wins a baseball game by\n",
    "    #Rating updater\n",
    "    blowout_proportion = abs(score1-score2) # Swings elo changes more in blowouts\n",
    "    normalized_blowout = blowout_proportion  / normal_win_factor\n",
    "    normalized_blowout = normalized_blowout ** 0.5 #Square root maps it closer to 1\n",
    "\n",
    "    return player_rating + k * normalized_blowout * (result - expectation)\n",
    "\n",
    "def resolveOneGame(i,df,k):\n",
    "\n",
    "    #Look at home and away teams\n",
    "    home = df.loc[i,'Home Team']\n",
    "    if home == \"Arizona D'Backs\":\n",
    "      home = \"Arizona Diamondbacks\"\n",
    "\n",
    "    away = df.loc[i,'Away Team']\n",
    "    if away == \"Arizona D'Backs\":\n",
    "      away = \"Arizona Diamondbacks\"\n",
    "    #print(home,away)\n",
    "\n",
    "    #Get Codes\n",
    "    home_code = mlb_teams[home]\n",
    "    away_code = mlb_teams[away]\n",
    "\n",
    "    #Look up their ratings\n",
    "    helo = ratings[home_code]\n",
    "    aelo = ratings[away_code]\n",
    "    exp= expectation(helo,aelo)\n",
    "    #print(aelo,helo,exp)\n",
    "\n",
    "    #Look up the game scores\n",
    "    homescore = df.loc[i,'R Home']\n",
    "    awayscore = df.loc[i,'R Away']\n",
    "\n",
    "    #Stores their ratings from before (potentially usefull later)\n",
    "    bhratings = ratings[home_code]\n",
    "    baratings = ratings[away_code]\n",
    "\n",
    "    #Updates ratings based on game outcome\n",
    "    if homescore > awayscore:\n",
    "        ratings[home_code] = update_rating(exp,helo,1,homescore,awayscore,k)\n",
    "        ratings[away_code] = update_rating(1-exp,aelo,0,homescore,awayscore,k)\n",
    "    elif homescore < awayscore:\n",
    "        ratings[home_code] = update_rating(exp,helo,0,homescore,awayscore,k)\n",
    "        ratings[away_code] = update_rating(1-exp,aelo,1,homescore,awayscore,k)\n",
    "    else:\n",
    "        ratings[home_code] = update_rating(exp,helo,0.5,homescore,awayscore,k)\n",
    "        ratings[away_code] = update_rating(1-exp,aelo,0.5,homescore,awayscore,k)\n",
    "\n",
    "    #Not strictly necessary but I used it when scraping the 2023 data\n",
    "    return bhratings, baratings\n",
    "\n",
    "def resolve_all_games(df_new):\n",
    "    #Edited to give a heavier weight to games played more recently\n",
    "    recent_games = 60\n",
    "    inclusion = len(df_new) - recent_games\n",
    "    for i in range(len(df_new)):\n",
    "        if k_boost == True:\n",
    "            if i < inclusion:\n",
    "                k = 20\n",
    "            else:\n",
    "                k = 40\n",
    "        else:\n",
    "            k = 20\n",
    "        resolveOneGame(i,df_new, k)\n",
    "\n",
    "\n",
    "def trainNueralNet(df):\n",
    "\n",
    "  #Convert dataframe data into y data\n",
    "  #y_tuple = np.array([list(row) for row in df[['R Home', 'R Away']].values])\n",
    "  y_tuple = np.array([[row[0], row[1], row[0] + row[1], row[0]-row[1]] for row in df[['R Home', 'R Away']].values])\n",
    "\n",
    "  #Doing the same for x\n",
    "  x_tuple = np.array([list(row) for row in df[['Home Rating', 'Away Rating', 'HomePitcherERA', 'AwayPitcherERA','Home avg Runs', 'Away avg Runs']].values.astype(float)])\n",
    "\n",
    "  #Train Test Split\n",
    "  ts = 0.2\n",
    "  rs = np.random.randint(20,60)\n",
    "  print(f\"Random seed = {rs}\")\n",
    "  x_train, x_test, y_train, y_test = train_test_split(x_tuple, y_tuple, test_size=ts, random_state=rs)\n",
    "\n",
    "  #Normalize data\n",
    "  global scaler\n",
    "  scaler = MinMaxScaler()\n",
    "  X_normalized = scaler.fit_transform(x_train)\n",
    "\n",
    "  global scalerY\n",
    "  scalerY = PowerTransformer(method = 'yeo-johnson')\n",
    "\n",
    "  Y_normalized = scalerY.fit_transform(y_train)\n",
    "\n",
    "  #Global\n",
    "  global model\n",
    "  model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(16, activation='relu', input_shape=(6,)),  # Input layer\n",
    "        layers.Dropout(0.5),  # dropout rate of 0.5\n",
    "        tf.keras.layers.Dense(48, activation='relu'),  # Hidden layer\n",
    "        tf.keras.layers.Dense(32, activation='relu'),  # Hidden layer\n",
    "        tf.keras.layers.Dense(16, activation='relu'),  # Hidden layer\n",
    "        tf.keras.layers.Dense(4)  # Output layer with 2 neurons for 2 output features\n",
    "    ])\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(optimizer='adam', loss=tf.keras.losses.Huber(), metrics=['mae'])\n",
    "\n",
    "  # Train the model\n",
    "  history = model.fit(X_normalized, Y_normalized, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "  # Evaluate the model\n",
    "  loss, mae = model.evaluate(x_test, y_test)\n",
    "\n",
    "  print(f\"Test Loss: {loss}\")\n",
    "  print(f\"Test MAE: {mae}\")\n",
    "\n",
    "  return x_train, x_test, y_train, y_test\n",
    "\n",
    "def getNNpreds(home_rating, away_rating, homeERA, awayERA,homeAvgRun, awayAvgRun):\n",
    "  X = np.array([[home_rating, away_rating, homeERA, awayERA,homeAvgRun, awayAvgRun]])\n",
    "  X_norm = scaler.transform(X)\n",
    "\n",
    "  #Blocks a print line\n",
    "  with redirect_stdout(stopper):\n",
    "\n",
    "    #Makes predictions\n",
    "    prediction = model.predict(X_norm)\n",
    "    prediction = scalerY.inverse_transform(prediction)\n",
    "    prediction = prediction*1.0625\n",
    "\n",
    "  return prediction\n",
    "\n",
    "def evaluateModel(x_test, y_test):\n",
    "    \n",
    "    #Initialize counters\n",
    "    home_win_pred = 0\n",
    "    home_win_wrong = 0\n",
    "    away_win_pred = 0\n",
    "    away_win_wrong = 0\n",
    "    \n",
    "    high_pred = 0\n",
    "    high_wrong = 0\n",
    "    low_pred = 0\n",
    "    low_wrong = 0\n",
    "\n",
    "    score_dif = []\n",
    "    outcome = []\n",
    "\n",
    "    #Loop through test data and update counters\n",
    "    for i in range(len(y_test)):\n",
    "    \n",
    "        #Home vs away\n",
    "        pred = getNNpreds(x_test[i][0],x_test[i][1],x_test[i][2],x_test[i][3],x_test[i][4],x_test[i][5])\n",
    "        score_dif.append(pred[0][0]-pred[0][1])\n",
    "        if y_test[i][0] > y_test[i][1]:\n",
    "          #Home win\n",
    "          outcome.append(1)\n",
    "          if pred[0][0] > pred[0][1]:\n",
    "            #Home predicted to win\n",
    "            home_win_pred += 1\n",
    "          else:\n",
    "            home_win_wrong += 1\n",
    "        else:\n",
    "          #Away win\n",
    "          outcome.append(0)\n",
    "          if pred[0][0] < pred[0][1]:\n",
    "            #Away predicted to win\n",
    "            away_win_pred += 1\n",
    "          else:\n",
    "            away_win_wrong += 1\n",
    "        \n",
    "        #High scoring vs low scoring\n",
    "        true_score = y_test[i][0] + y_test[i][1]\n",
    "        pred_score = pred[0][0] + pred[0][1]\n",
    "        \n",
    "        if true_score > 8.5:\n",
    "          if pred_score > 8.5:\n",
    "            high_pred +=1\n",
    "          else:\n",
    "            high_wrong += 1\n",
    "        else:\n",
    "          if pred_score < 8.5:\n",
    "            low_pred += 1\n",
    "          else:\n",
    "            low_wrong += 1\n",
    "        \n",
    "        #Give feedback on how long it might take\n",
    "        if i%100 == 0:\n",
    "          print(f\"The model has run prediction {i} out of {len(y_test)}\")\n",
    "        \n",
    "    #Plotting\n",
    "    confusion_matrix_ha = np.array([[home_win_pred, home_win_wrong],\n",
    "                            [away_win_wrong, away_win_pred]])\n",
    "    plt.imshow(confusion_matrix_ha, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix (Home vs away)')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Winner prediction: Home (left) vs Away (right)')\n",
    "    plt.ylabel('True Outcome: Home Win (top) vs Away Win (bottom)')\n",
    "    for i in range(2):\n",
    "      for j in range(2):\n",
    "          plt.text(j, i, str(confusion_matrix_ha[i][j]), ha='center', va='center', color='orange')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    confusion_matrix_hl = np.array([[high_pred, high_wrong],\n",
    "                            [low_wrong,low_pred]])\n",
    "    plt.imshow(confusion_matrix_hl, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix (High vs Low Scoring)')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Score prediction: High (left) vs Low (right)')\n",
    "    plt.ylabel('True Outcome: High (top) vs Low (bottom)')\n",
    "    for i in range(2):\n",
    "      for j in range(2):\n",
    "          plt.text(j, i, str(confusion_matrix_hl[i][j]), ha='center', va='center', color='orange')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "  #Return how many games the model successfuly predicted\n",
    "    return home_win_pred + away_win_pred, home_win_wrong + away_win_wrong, score_dif, outcome\n",
    "\n",
    "def binomialTest(right,wrong):\n",
    "  # Total number of trials\n",
    "  n_trials = right + wrong\n",
    "  print(f\"Correct Fraction: {right/n_trials}\")\n",
    "  # Probability of success for a fair coin flip (0.5)\n",
    "  p_null = 0.5\n",
    "\n",
    "  # Perform binomial test\n",
    "  result = binomtest(right, n_trials, p_null)\n",
    "  p_value = result.pvalue\n",
    "\n",
    "  # Print the p-value\n",
    "  print(f\"The p-value for the binomial test is: {p_value}\")\n",
    "\n",
    "  # Check if the process guesses better than a coin flip\n",
    "  alpha = 0.05  # significance level\n",
    "  if p_value < alpha:\n",
    "      print(\"The nueral net guesses the winner better than a coin flip (reject the null hypothesis).\")\n",
    "  else:\n",
    "      print(\"The nueral net does cannot be said to guess better than a coin flip (fail to reject the null hypothesis at a significance level of 0.05).\")\n",
    "  return p_value\n",
    "\n",
    "def logistic_regression(score_dif, outcome):\n",
    "    if trainer == 'train':\n",
    "        global score2prob\n",
    "        score2prob = LogisticRegression()\n",
    "    X = np.array(score_dif).reshape(-1, 1)\n",
    "    #print(X)\n",
    "    Y = np.array(outcome)\n",
    "    #print(Y)\n",
    "    if trainer == 'train':\n",
    "        score2prob.fit(X, Y)\n",
    "    \n",
    "    # Predict probabilities for the test set\n",
    "    y_pred_proba = score2prob.predict_proba(X)[:, 1]  # Probability of class 1 (home team wins)\n",
    "    \n",
    "    # Convert probabilities to binary outcomes based on a threshold (e.g., 0.5)\n",
    "    threshold = 0.5\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    print(\"Logistic Regression Training Report\")\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(Y, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(classification_report(Y, y_pred))\n",
    "    \n",
    "\n",
    "def initialize_k_booster():\n",
    "    k_booster = input(\"Enter k to turn on k boosting. This makes the model more sensitive to the results of recent games. \")\n",
    "    global k_boost\n",
    "    k_boost = False\n",
    "    if k_booster == \"k\":\n",
    "        k_boost = True\n",
    "\n",
    "\n",
    "def promptForData():\n",
    "\n",
    "    try:\n",
    "        #Take inputs\n",
    "        home_team = input(\"Enter the home team: \")\n",
    "        home_id = mlb_teams[home_team]\n",
    "        away_team = input(\"Enter the away team: \")\n",
    "        away_id = mlb_teams[away_team]\n",
    "        home_era = float(input(\"Enter the ERA of the home pitcher: \"))\n",
    "        away_era = float(input(\"Enter the ERA of the away pitcher: \"))\n",
    "        raway = float(ratings[away_id])\n",
    "        rhome = float(ratings[home_id])\n",
    "        avgHome = totals[home_id][0]/totals[home_id][1]\n",
    "        avgAway = totals[away_id][0]/totals[away_id][1]\n",
    "        \n",
    "        #Printing\n",
    "        print(f\"{home_team}: {rhome} {away_team}: {raway}\")\n",
    "        #Finding probability of a home win\n",
    "        prob = expectation(rhome,raway)\n",
    "        print(f\"According to the elos, {home_team} have a {prob} chance of winning while {away_team} have a {1 - prob} chance. This does not take into acount additional information like ERAs.\")\n",
    "        prediction = getNNpreds(rhome, raway, home_era, away_era,avgHome,avgAway)\n",
    "        print(f\"{home_team} score prediction: {prediction[0][0]}\")\n",
    "        print(f\"{away_team} score prediction: {prediction[0][1]}\")\n",
    "        difference = [[ prediction[0][0]-prediction[0][1] ]]\n",
    "        logpred = score2prob.predict_proba(difference)\n",
    "        print(f\"Running logistic regression on the score difference suggests that {home_team} have a {logpred[0][1]} chance of winning while {away_team} have a {logpred[0][0]} chance.\")\n",
    "        print()\n",
    "        if kel == True:\n",
    "            if logpred[0][1] > logpred[0][0]:\n",
    "                kelly(logpred[0][1], home_team)\n",
    "            else:\n",
    "                kelly(logpred[0][0], away_team)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        # Handle the user entering something that would cause an error\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print()\n",
    "\n",
    "def imports(df):\n",
    "    \n",
    "    global model\n",
    "    model = tf.keras.models.load_model(r'C:\\Users\\Jack Leitzell\\Downloads\\MLBPredictor5.7.2024')\n",
    "\n",
    "    global score2prob\n",
    "    score2prob = load('score2prob.joblib')\n",
    "\n",
    "    global scaler\n",
    "    scaler = load('scaler.joblib')\n",
    "\n",
    "    global scalerY\n",
    "    scalerY = load('scalerY.joblib')\n",
    "\n",
    "    eval = input(\"Do you want to see model evaluations? (y/n) \")\n",
    "    if eval == 'y':\n",
    "    \n",
    "        #Convert dataframe data into y data\n",
    "        #y_tuple = np.array([list(row) for row in df[['R Home', 'R Away']].values])\n",
    "        y_tuple = np.array([[row[0], row[1], row[0] + row[1], row[0]-row[1]] for row in df[['R Home', 'R Away']].values])\n",
    "        \n",
    "        #Doing the same for x\n",
    "        x_tuple = np.array([list(row) for row in df[['Home Rating', 'Away Rating', 'HomePitcherERA', 'AwayPitcherERA','Home avg Runs', 'Away avg Runs']].values.astype(float)])\n",
    "        \n",
    "        #Train Test Split\n",
    "        ts = 0.2\n",
    "        rs = np.random.randint(20,60)\n",
    "        print(f\"Random seed = {rs}\")\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_tuple, y_tuple, test_size=ts, random_state=rs)\n",
    "        right, wrong, score_dif,outcome = evaluateModel(x_test, y_test)\n",
    "        binomialTest(right,wrong)\n",
    "        logistic_regression(score_dif, outcome)\n",
    "\n",
    "def kel_setup():\n",
    "    ks = input(\"Enter the value of your account if you wish to run Kelly fractions on the predictions. Otherwise click enter. \")\n",
    "    global kel\n",
    "    try:\n",
    "        global act_val\n",
    "        act_val = float(ks)\n",
    "        kel = True\n",
    "    except ValueError:\n",
    "        kel = False\n",
    "\n",
    "def american_to_decimal(american_odds):\n",
    "    if american_odds > 0:\n",
    "        final = 100 + american_odds\n",
    "        original = 100\n",
    "    else:\n",
    "        original = abs(american_odds)\n",
    "        final = 100 + original\n",
    "    return (final - original)/original\n",
    "    \n",
    "def kelly(winprob, name):\n",
    "    try:\n",
    "        american_odds = float(input(f\"Enter the American odds that the {name} win: \"))\n",
    "        decimal_odds = american_to_decimal(american_odds)\n",
    "        q = 1 - winprob\n",
    "        frac = winprob - q/decimal_odds\n",
    "        if frac > 0:\n",
    "            print(f\"The Kelly fraction would be to bet {frac*100}% of your money.\")\n",
    "            print(f\"Given your current account value this ammounts to ${frac * act_val}.\")\n",
    "            print(f\"At 50% Kelly you should instead bet ${frac * act_val*0.50}.\")\n",
    "        else:\n",
    "            print(\"There is no profitable bet availible on this game\")\n",
    "    except Error:\n",
    "        print(\"It seems like you entered the odds incorrectly.\")\n",
    "    print()\n",
    "            \n",
    "            \n",
    "\n",
    "def main():\n",
    "    global trainer\n",
    "    trainer = input('Enter \"train\" to retrain the models. Otherwise defaults to models trained on 5/7/2024. ')\n",
    "    kel_setup()\n",
    "    df_hist = readInHistoricalData()\n",
    "    initialize_k_booster()\n",
    "    global ratings\n",
    "    \n",
    "    ratings = get_last_ratings(df_hist)\n",
    "    regressLastYearRatingsToMean()\n",
    "    newDf = scrapeLatestData()\n",
    "    populateTotals(newDf)\n",
    "    resolve_all_games(newDf)\n",
    "    if trainer == 'train':\n",
    "        x_train, x_test, y_train, y_test = trainNueralNet(df_hist)\n",
    "        right, wrong, score_dif,outcome = evaluateModel(x_test, y_test)\n",
    "        binomialTest(right,wrong)\n",
    "        logistic_regression(score_dif, outcome)\n",
    "    else:\n",
    "        imports(df_hist)\n",
    "    while True:\n",
    "        promptForData()\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f300d28-c36c-49ac-a586-21ba441d74b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jack Leitzell\\Downloads\\MLBPredictor5.7.2024\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['score2prob.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(r'C:\\Users\\Jack Leitzell\\Downloads\\MLBPredictor5.7.2024')\n",
    "from joblib import dump\n",
    "\n",
    "# Assuming 'model' is your trained scikit-learn model\n",
    "dump(score2prob, 'score2prob.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ef0d118-1a3e-47cf-9d86-d87e7cefd779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scalerY.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Assuming 'normalization_model_1' and 'normalization_model_2' are your fitted normalization models\n",
    "dump(scaler, 'scaler.joblib')\n",
    "dump(scalerY, 'scalerY.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
